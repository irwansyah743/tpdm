{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a72600",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3062355716.py, line 136)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(classification_report(Y_validation, predictions))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#-------------------------------------------------------------\n",
    "#Reading file from \\\"Tweet.csv\\\"\n",
    "def baca_file():\n",
    "\n",
    "    csvF1 = \"Tweet.csv\"\n",
    "    \n",
    "    #Open file Tweet.csv to manipulate \n",
    "    \n",
    "    with open(csvF1,\"r\") as rCsv:\n",
    "            \n",
    "        readCsv = csv.reader(rCsv, delimiter = ';')\n",
    "        read = []\n",
    "        for row in readCsv:\n",
    "            if len(row) != 0:\n",
    "               read = read + [row]\n",
    "\n",
    "    rCsv.close()\n",
    "    return(read)\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    #Procedure for displaying the result to the console\n",
    "\n",
    "def tampil_csv(f2):\n",
    "    df3 = pd.DataFrame(f2)\n",
    "    print(df3)\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    #Function stemming and return the value of feature and target\n",
    "def stemmingFile(fCsv):\n",
    "\n",
    "       #---Define a new list for temporary reading---#\n",
    "    rList = []\n",
    "    eList =[]\n",
    "    #---initialization a stopword by Sastrawi---#\n",
    "    facto  = StopWordRemoverFactory()\n",
    "    stopwords = facto.create_stop_word_remover()\n",
    "    #---Looping to read line by line csv file---#\n",
    "    for idx in fCsv:\n",
    "        rList.append(stopwords.remove(idx[0]))\n",
    "        #---change every word in target to new value---#\n",
    "        if idx[1] == 'Keluhan':\n",
    "            eList.append('1')\n",
    "        elif idx[1]== 'Respon':\n",
    "            eList.append('2')\n",
    "        else:\n",
    "            eList.append('3')\n",
    "        #--- end of IF ---#\n",
    "    #--- end of looping ---#\n",
    "    return (rList,eList)#parameter return\n",
    "    #-------------------------------------------------------------\n",
    "#procedure to classify every sample in Tweeter.csv\n",
    "def classiLogRegressi(lRead, rRead):\n",
    "    #---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(lRead, rRead, \n",
    "test_size=validation_size, random_state=seed)\n",
    "    #---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "    \n",
    "    print('Logistic Regresion')\n",
    "    logistic = 'LogisticRegression'()\n",
    "    logistic = Pipeline([\n",
    "    ('xPipe',w),\n",
    "    ('knn', logistic)])\n",
    "    logistic.fit(X_train, Y_train)\n",
    "    predictions = logistic.predict(X_validation)\n",
    "    \n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "    return(logistic)\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "def classKNeighborsClassifier(lRead, rRead):\n",
    "    #---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(lRead, rRead, \n",
    "test_size=validation_size, random_state=seed)\n",
    "\n",
    "    #---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "    \n",
    "    #---classification using K-NN---#\n",
    "    print('K-Neighborhood' )\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn = Pipeline([\n",
    "    ('xPipe',w),\n",
    "    ('knn', logistic)])\n",
    "    knn.fit(X_train, Y_train)\n",
    "    predictions = knn.predict(X_validation)\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "    \n",
    "    return(knn)\n",
    "\n",
    "    #-------------------------------------------------------------\n",
    "def classDecisionTree(lRead, rRead):\n",
    "    #---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(lRead, rRead, \n",
    "test_size=validation_size, random_state=seed)\n",
    "    \n",
    "    #---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "    \n",
    "    #---classification using K-NN---# \n",
    "    print('Decision Tree')\n",
    "    deTree = DecisionTreeClassifier()\n",
    "    deTree = Pipeline([\n",
    "    ('xPipe',w),\n",
    "    ('knn', deTree)])\n",
    "    deTree.fit(X_train, Y_train)\n",
    "    predictions = deTree.predict(X_validation)\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions)\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "          \n",
    "    return(deTree)\n",
    "          \n",
    "          \n",
    "    #----------------------------------------------------------------\n",
    "def singleTextLogisticRegression(xText, mknn):\n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = mknn.predict(x_test)\n",
    "    return(mpredictions)\n",
    "    #----------------------------------------------------------------\n",
    "    def singleTextKNeighbor(xText, cKboar):  \n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = cKboar.predict(x_test)\n",
    "    return(mpredictions)\n",
    "    #-----------------------------------------------------------------\n",
    "\n",
    "def singleTextDecisionTree(xText, dTree):\n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = dTree.predict(x_test)\n",
    "    return(mpredictions)\n",
    "    #-----------------------------------------------------------------\n",
    "def singleTextNaiveBayes(xText, mBayes):   \n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = mBayes.predict(x_test)\n",
    "\n",
    "    return(mpredictions)\n",
    "    #-----------------------------------------------------------------\n",
    "def konversiPrediksi(pre):\n",
    "    tulis = '',\n",
    "    if pre == '1':\n",
    "        tulis = 'Keluhan'\n",
    "    elif pre== '2':\n",
    "        tulis = 'Respon'\n",
    "    else:\n",
    "        tulis = Not Keluhan/Respon \n",
    "    return(tulis)\n",
    "    #-----Program utama----------------------------------------------- \n",
    "if __name__ == '__main__':\n",
    "    dList, fList = stemmingFile(baca_file())\n",
    "    #---model logistic regression---\n",
    "    logRes   = classiLogRegressi(dList, fList)\n",
    "    Neighbor = classKNeighborsClassifier(dList, fList)\n",
    "    DesTree  = classDecisionTree(dList, fList)\n",
    "    testing = input('Masukkan text tweet' = )\n",
    "    l = singleTextLogisticRegression(testing, logRes)\n",
    "    k = singleTextKNeighbor(testing, Neighbor)\n",
    "    t = singleTextDecisionTree(testing, DesTree)\n",
    "\n",
    "\n",
    "    print('Prediksi dengan Logistic Regression = ',konversiPrediksi(l))\n",
    "    print('Prediksi dengan K-Nearest Neighirhood = ',konversiPrediksi(k))\n",
    "    print('Prediksi dengan Decision Tree = ', konversiPrediksi(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af24b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721f325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7d128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
